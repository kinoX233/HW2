@@ -20,6 +20,9 @@
 import torchvision.transforms as transforms
 from torch.optim.lr_scheduler import StepLR
 from torch.utils.data import Subset
+import pandas as pd
+from torchvision.io import read_image
+from torch.utils.tensorboard import SummaryWriter

 model_names = sorted(name for name in models.__dict__
     if name.islower() and not name.startswith("__")
@@ -144,6 +147,10 @@
         print("=> creating model '{}'".format(args.arch))
         model = models.__dict__[args.arch]()

+    #?change output to 200
+    model.fc = nn.Linear(512,200)
+    model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
+
     if not torch.cuda.is_available() and not torch.backends.mps.is_available():
         print('using CPU, this will be slow')
     elif args.distributed:
@@ -222,31 +229,32 @@
             print("=> no checkpoint found at '{}'".format(args.resume))


-    # Data loading code
+    # Data loading code
     if args.dummy:
         print("=> Dummy data is used!")
         train_dataset = datasets.FakeData(1281167, (3, 224, 224), 1000, transforms.ToTensor())
         val_dataset = datasets.FakeData(50000, (3, 224, 224), 1000, transforms.ToTensor())
     else:
         traindir = os.path.join(args.data, 'train')
-        valdir = os.path.join(args.data, 'val')
+        valdir = os.path.join(args.data, 'val_new_2')
         normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                      std=[0.229, 0.224, 0.225])

-        train_dataset = datasets.ImageFolder(
+    train_dataset = datasets.ImageFolder(
             traindir,
             transforms.Compose([
-                transforms.RandomResizedCrop(224),
-                transforms.RandomHorizontalFlip(),
+                #transforms.RandomResizedCrop(64),
+                #transforms.RandomHorizontalFlip(),
+                transforms.Resize(64),
                 transforms.ToTensor(),
                 normalize,
             ]))
-
-        val_dataset = datasets.ImageFolder(
+
+    val_dataset = datasets.ImageFolder(
             valdir,
             transforms.Compose([
-                transforms.Resize(256),
-                transforms.CenterCrop(224),
+                #transforms.CenterCrop(64),
+                transforms.Resize(64),
                 transforms.ToTensor(),
                 normalize,
             ]))
@@ -308,7 +316,10 @@
         len(train_loader),
         [batch_time, data_time, losses, top1, top5],
         prefix="Epoch: [{}]".format(epoch))
-
+
+    #tensorboard
+    writer = SummaryWriter()
+
     # switch to train mode
     model.train()

@@ -331,6 +342,9 @@
         top1.update(acc1[0], images.size(0))
         top5.update(acc5[0], images.size(0))

+        writer.add_scalar('loss',losses.val,global_step=epoch * len(train_loader) + i)
+        writer.add_scalar('top5',top5.val,global_step=epoch * len(train_loader) + i)
+
         # compute gradient and do SGD step
         optimizer.zero_grad()
         loss.backward()
@@ -343,10 +357,15 @@
         if i % args.print_freq == 0:
             progress.display(i + 1)

+    writer.close()
+

 def validate(val_loader, model, criterion, args):

     def run_validate(loader, base_progress=0):
+        #tensorboard
+        writer = SummaryWriter()
+
         with torch.no_grad():
             end = time.time()
             for i, (images, target) in enumerate(loader):
@@ -369,6 +388,9 @@
                 top1.update(acc1[0], images.size(0))
                 top5.update(acc5[0], images.size(0))

+                writer.add_scalar('val_loss',losses.val,global_step=len(loader) + i)
+                writer.add_scalar('val_top5',top5.val,global_step=len(loader) + i)
+
                 # measure elapsed time
                 batch_time.update(time.time() - end)
                 end = time.time()
@@ -376,6 +398,8 @@
                 if i % args.print_freq == 0:
                     progress.display(i + 1)

+        writer.close()
+
     batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)
     losses = AverageMeter('Loss', ':.4e', Summary.NONE)
     top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)
